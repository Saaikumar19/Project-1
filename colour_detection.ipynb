{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOkmJxK3o7LTXm9TLCnzTCT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jason04-08-2005/ai_chat_bot-/blob/colour-detection/colour_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 749
        },
        "id": "JSg1LledGNoh",
        "outputId": "2526beb4-cff6-4a63-9e0e-e41b6a3e48b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.1/54.1 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m323.1/323.1 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m79.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hIt looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://ce0edb43e5961d1b82.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://ce0edb43e5961d1b82.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# Step 1: Install required packages\n",
        "!pip install gradio pandas opencv-python-headless --quiet\n",
        "\n",
        "# Step 2: Import libraries\n",
        "import gradio as gr\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Step 3: Color dataset\n",
        "colors_data = [\n",
        "    (\"Red\", \"#FF0000\", 255, 0, 0),\n",
        "    (\"Green\", \"#00FF00\", 0, 255, 0),\n",
        "    (\"Blue\", \"#0000FF\", 0, 0, 255),\n",
        "    (\"White\", \"#FFFFFF\", 255, 255, 255),\n",
        "    (\"Black\", \"#000000\", 0, 0, 0),\n",
        "    (\"Gray\", \"#808080\", 128, 128, 128),\n",
        "    (\"Yellow\", \"#FFFF00\", 255, 255, 0),\n",
        "    (\"Cyan\", \"#00FFFF\", 0, 255, 255),\n",
        "    (\"Magenta\", \"#FF00FF\", 255, 0, 255),\n",
        "    (\"Orange\", \"#FFA500\", 255, 165, 0),\n",
        "    (\"Pink\", \"#FFC0CB\", 255, 192, 203),\n",
        "    (\"Brown\", \"#A52A2A\", 165, 42, 42),\n",
        "    (\"Purple\", \"#800080\", 128, 0, 128),\n",
        "    (\"Maroon\", \"#800000\", 128, 0, 0),\n",
        "    (\"Olive\", \"#808000\", 128, 128, 0),\n",
        "    (\"Navy\", \"#000080\", 0, 0, 128),\n",
        "    (\"Teal\", \"#008080\", 0, 128, 128),\n",
        "    (\"Silver\", \"#C0C0C0\", 192, 192, 192),\n",
        "    (\"Gold\", \"#FFD700\", 255, 215, 0)\n",
        "]\n",
        "df = pd.DataFrame(colors_data, columns=[\"color_name\", \"hex\", \"R\", \"G\", \"B\"])\n",
        "\n",
        "# Step 4: Function to find closest color\n",
        "def get_closest_color_name(r, g, b):\n",
        "    minimum = float('inf')\n",
        "    closest_name = \"\"\n",
        "    for _, row in df.iterrows():\n",
        "        d = abs(r - row[\"R\"]) + abs(g - row[\"G\"]) + abs(b - row[\"B\"])\n",
        "        if d < minimum:\n",
        "            minimum = d\n",
        "            closest_name = row[\"color_name\"]\n",
        "    return closest_name\n",
        "\n",
        "# Step 5: Function to handle image click\n",
        "def detect_color(image, event: gr.SelectData):\n",
        "    if image is None or event is None:\n",
        "        return \"No image or click\", \"#ffffff\"\n",
        "\n",
        "    y, x = event.index[1], event.index[0]  # event.index is (x, y)\n",
        "    pixel = image[y, x]\n",
        "    r, g, b = int(pixel[0]), int(pixel[1]), int(pixel[2])\n",
        "    color_name = get_closest_color_name(r, g, b)\n",
        "    color_text = f\"{color_name} (R={r}, G={g}, B={b})\"\n",
        "    return color_text, f\"rgb({r},{g},{b})\"\n",
        "\n",
        "# Step 6: Gradio Interface\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## ğŸ¨ Color Detection Tool (Click anywhere on the image)\")\n",
        "    with gr.Row():\n",
        "        image_input = gr.Image(type=\"numpy\", label=\"Upload Image\")\n",
        "        color_info = gr.Textbox(label=\"Color Name and RGB\")\n",
        "        color_box = gr.ColorPicker(label=\"Detected Color\", value=\"#ffffff\")\n",
        "\n",
        "    image_input.select(fn=detect_color, inputs=[image_input], outputs=[color_info, color_box])\n",
        "\n",
        "demo.launch()\n"
      ]
    }
  ]
}